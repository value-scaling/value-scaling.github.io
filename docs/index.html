<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link
      rel="preload"
      href="./fonts/ibm_plex_sans/IBMPlexSans-Regular.ttf"
      as="font"
      type="font/ttf"
      crossorigin
    />
    <link
      rel="preload"
      href="./fonts/newsreader/Newsreader_14pt-Italic.ttf"
      as="font"
      type="font/ttf"
      crossorigin
    />
    <link rel="icon" href="./favicon.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=G-ZSV2YDNY0W"
    ></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());
      gtag("config", "G-ZSV2YDNY0W", { send_page_view: false });
    </script>
    <script>
      if (window.location.hostname === "localhost") {
        window.gtag = () => {};
      }
    </script>
    
		<link href="./_app/immutable/assets/0.Cg0gL2Q5.css" rel="stylesheet">
		<link href="./_app/immutable/assets/2.Br9QgzWw.css" rel="stylesheet">
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_AMS-Regular.BQhdFMY1.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_AMS-Regular.DMm9YOAa.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_AMS-Regular.DRggAlZN.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Caligraphic-Bold.Dq_IR9rO.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Caligraphic-Bold.BEiXGLvX.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Caligraphic-Bold.ATXxdsX0.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Caligraphic-Regular.Di6jR-x-.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Caligraphic-Regular.CTRA-rTL.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Caligraphic-Regular.wX97UBjC.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Fraktur-Bold.CL6g_b3V.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Fraktur-Bold.BsDP51OF.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Fraktur-Bold.BdnERNNW.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Fraktur-Regular.CTYiF6lA.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Fraktur-Regular.Dxdc4cR9.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Fraktur-Regular.CB_wures.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Main-Bold.Cx986IdX.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Main-Bold.Jm3AIy58.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Main-Bold.waoOVXN0.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Main-BoldItalic.DxDJ3AOS.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Main-BoldItalic.SpSLRI95.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Main-BoldItalic.DzxPMmG6.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Main-Italic.NWA7e6Wa.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Main-Italic.BMLOBm91.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Main-Italic.3WenGoN9.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Main-Regular.B22Nviop.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Main-Regular.Dr94JaBh.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Main-Regular.ypZvNtVU.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Math-BoldItalic.CZnvNsCZ.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Math-BoldItalic.iY-2wyZ7.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Math-BoldItalic.B3XSjfu4.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Math-Italic.t53AETM-.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Math-Italic.DA0__PXp.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Math-Italic.flOr_0UB.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_SansSerif-Bold.D1sUS0GD.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_SansSerif-Bold.DbIhKOiC.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_SansSerif-Bold.CFMepnvq.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_SansSerif-Italic.C3H0VqGB.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_SansSerif-Italic.DN2j7dab.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_SansSerif-Italic.YYjJ1zSn.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_SansSerif-Regular.DDBCnlJ7.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_SansSerif-Regular.CS6fqUqJ.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_SansSerif-Regular.BNo7hRIc.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Script-Regular.D3wIWfF6.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Script-Regular.D5yQViql.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Script-Regular.C5JkGWo-.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Size1-Regular.mCD8mA8B.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Size1-Regular.C195tn64.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Size1-Regular.Dbsnue_I.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Size2-Regular.Dy4dx90m.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Size2-Regular.oD1tc_U0.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Size2-Regular.B7gKUWhC.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Size3-Regular.CTq5MqoE.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Size3-Regular.DgpXs0kz.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Size4-Regular.Dl5lxZxV.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Size4-Regular.BF-4gkZK.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Size4-Regular.DWFBv043.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Typewriter-Regular.CO6r4hn1.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Typewriter-Regular.C0xS9mPB.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Typewriter-Regular.D3Ib7_Hf.ttf" crossorigin>
		<link rel="modulepreload" href="./_app/immutable/entry/start.NpdkYoDT.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/entry.CR_oJlUv.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/scheduler.BgYmKTTO.js">
		<link rel="modulepreload" href="./_app/immutable/entry/app.s2HBLhOM.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/index.A5wVaqv5.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/0.Vnueor7r.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/stores.CcZTnyfm.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/2.in6smNPM.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/each.BoQ2FUBB.js"><title>Scaling Laws for Value-Based RL</title><!-- HEAD_svelte-1r9of7h_START --><!-- HEAD_svelte-1r9of7h_END --><!-- HEAD_svelte-1u7ey3_START --><meta name="description" content="With the right design decisions, value-based RL admits predictable scaling."><meta property="og:title" content="Scaling Laws for Value-Based RL"><meta property="og:description" content="With the right design decisions, value-based RL admits predictable scaling."><!-- HEAD_svelte-1u7ey3_END -->
  </head>
  <body data-sveltekit-preload-data="hover">
    <div style="display: contents">   <header class="layout-md justify-between items-start" data-sveltekit-noscroll data-sveltekit-preload-code="eager" data-svelte-h="svelte-h16bjq"><div class="mb-8"><h1 class="font-bold text-black text-3xl mb-4">Scaling Laws for Value-Based RL</h1> <p class="text-black text-lg"><a href="https://prestonfu.com" class="link-no-underline">Preston Fu</a>,
      <a href="https://olehrybkin.com/" class="link-no-underline">Oleh Rybkin</a>,
      <a href="https://aviralkumar2907.github.io/" class="link-no-underline">Aviral Kumar</a> <br>
      UC Berkeley, CMU
      <br>
      September 2025</p></div>  </header> <main>  <div> <div class="scroll-meter svelte-lifq7d" aria-hidden="true"><div class="track svelte-lifq7d"><div class="gradient svelte-lifq7d" style=""></div> </div> </div> <div class="layout-md text-lg space-y-12"><div class="space-y-2"><section id="model_scaling" class="svelte-1w2o5k5"> <div role="group" class="block -mx-4 mb-4 px-4 py-4 transition-colors hover:bg-sky-50 bg-sky-50"><div class="grid grid-cols-4 gap-4"> <div class="col-span-4 md:col-span-1 unselectable"><div class="relative w-full max-w-80 mx-auto"><img src="/assets/images/model_scaling_before.png" alt="Compute-Optimal Scaling for Value-Based Deep RL preview image" class="w-full block"> <video class="absolute inset-0 w-full h-full object-cover pointer-events-none" style="opacity: 0; transition: opacity 160ms ease;" preload="metadata" muted loop playsinline aria-hidden="true" tabindex="-1" poster="/assets/images/model_scaling_before.png"><source src="/assets/images/model_scaling_3d.mp4" type="video/mp4"></video></div></div> <div class="col-span-4 md:col-span-3"><h3 class="text-black text-lg font-semibold mb-2 no-meter"><a class="link-no-underline mr-1" href="https://arxiv.org/abs/2508.14881" target="_blank">Compute-Optimal Scaling for Value-Based Deep RL</a> <small class="whitespace-nowrap text-neutral-500 text-base font-normal">August 2025</small></h3> <div class="text-sm reduced-spacing"><div class="md-output space-y-6 svelte-2uty9x"><div class="md-output svelte-2uty9x"><!-- HTML_TAG_START --><p><a href="https://www.prestonfu.com/" class="link" target="_blank" rel="external noopener noreferrer">Preston Fu</a>*,
<a href="https://olehrybkin.com/" class="link" target="_blank" rel="external noopener noreferrer">Oleh Rybkin</a>*,
<a href="https://zhouzypaul.github.io/" class="link" target="_blank" rel="external noopener noreferrer">Zhiyuan Zhou</a>,
<a href="https://scholar.google.com/citations?user=GnEVRtQAAAAJ&hl=en" class="link" target="_blank" rel="external noopener noreferrer">Michal Nauman</a>,
<a href="https://people.eecs.berkeley.edu/~pabbeel/" class="link" target="_blank" rel="external noopener noreferrer">Pieter Abbeel</a>,
<a href="https://people.eecs.berkeley.edu/~svlevine/" class="link" target="_blank" rel="external noopener noreferrer">Sergey Levine</a>,
<a href="https://aviralkumar2907.github.io/" class="link" target="_blank" rel="external noopener noreferrer">Aviral Kumar</a></p>
<p><em>NeurIPS</em>, 2025</p>
<!-- HTML_TAG_END --></div> </div></div> <div class="flex flex-wrap gap-2"><a href="https://arxiv.org/abs/2508.14881" target="_blank" class="px-2 py-1 bg-sky-700 text-white text-[0.9rem] leading-[1rem] rounded hover:bg-sky-800 transition unselectable">arXiv </a><a href="https://github.com/prestonfu/model_scaling" target="_blank" class="px-2 py-1 bg-sky-700 text-white text-[0.9rem] leading-[1rem] rounded hover:bg-sky-800 transition unselectable">Code </a><a href="https://x.com/preston_fu/status/1962920781387882841" target="_blank" class="px-2 py-1 bg-sky-700 text-white text-[0.9rem] leading-[1rem] rounded hover:bg-sky-800 transition unselectable">Thread </a></div></div></div>  </div>  </section><section id="utd_scaling" class="svelte-1w2o5k5"> <div role="group" class="block -mx-4 mb-4 px-4 py-4 transition-colors hover:bg-sky-50 bg-sky-50"><div class="grid grid-cols-4 gap-4"> <div class="col-span-4 md:col-span-1 unselectable"><div class="relative w-full max-w-80 mx-auto"><img src="/assets/images/qscaled_before.png" alt="Value-Based Deep RL Scales Predictably preview image" class="w-full block"> </div></div> <div class="col-span-4 md:col-span-3"><h3 class="text-black text-lg font-semibold mb-2 no-meter"><a class="link-no-underline mr-1" href="https://arxiv.org/abs/2502.04327" target="_blank">Value-Based Deep RL Scales Predictably</a> <small class="whitespace-nowrap text-neutral-500 text-base font-normal">February 2025</small></h3> <div class="text-sm reduced-spacing"><div class="md-output space-y-6 svelte-2uty9x"><div class="md-output svelte-2uty9x"><!-- HTML_TAG_START --><p><a href="https://olehrybkin.com/" class="link" target="_blank" rel="external noopener noreferrer">Oleh Rybkin</a>,
<a href="https://scholar.google.com/citations?user=GnEVRtQAAAAJ&hl=en" class="link" target="_blank" rel="external noopener noreferrer">Michal Nauman</a>,
<a href="https://www.prestonfu.com/" class="link" target="_blank" rel="external noopener noreferrer">Preston Fu</a>,
<a href="https://sea-snell.github.io/" class="link" target="_blank" rel="external noopener noreferrer">Charlie Snell</a>,
<a href="https://people.eecs.berkeley.edu/~pabbeel/" class="link" target="_blank" rel="external noopener noreferrer">Pieter Abbeel</a>,
<a href="https://people.eecs.berkeley.edu/~svlevine/" class="link" target="_blank" rel="external noopener noreferrer">Sergey Levine</a>,
<a href="https://aviralkumar2907.github.io/" class="link" target="_blank" rel="external noopener noreferrer">Aviral Kumar</a></p>
<p><em>ICML</em>, 2025 <br><em>ICLR Robot Learning Workshop</em>, 2025 (<strong>oral</strong>)</p>
<!-- HTML_TAG_END --></div> </div></div> <div class="flex flex-wrap gap-2"><a href="https://arxiv.org/abs/2502.04327" target="_blank" class="px-2 py-1 bg-sky-700 text-white text-[0.9rem] leading-[1rem] rounded hover:bg-sky-800 transition unselectable">arXiv </a><a href="https://github.com/prestonfu/qscaled" target="_blank" class="px-2 py-1 bg-sky-700 text-white text-[0.9rem] leading-[1rem] rounded hover:bg-sky-800 transition unselectable">Code </a><a href="https://x.com/_oleh/status/1889016893140516880" target="_blank" class="px-2 py-1 bg-sky-700 text-white text-[0.9rem] leading-[1rem] rounded hover:bg-sky-800 transition unselectable">Thread </a><a href="/assets/files/utd_scaling_poster_icml.pdf" target="_blank" class="px-2 py-1 bg-sky-700 text-white text-[0.9rem] leading-[1rem] rounded hover:bg-sky-800 transition unselectable">Poster </a></div></div></div>  </div>  </section></div></div> <div class="layout-md text-lg space-y-12"><div class="md-output space-y-6 svelte-2uty9x"><div class="md-output svelte-2uty9x"><!-- HTML_TAG_START --><p>In the era of large-scale AI, it is important to prototype new training methodologies at small scales before running at large scales or datasets. This workflow only works if the training outcomes are predictable — we need experimentation workflows for which results at small scale can reliably forecast behavior at large scale without running the full experiment. To build predictable workflows, the community has followed the path of estimating <em>scaling laws</em>: rules that fit the target performance metric as a function of resources (e.g., data, compute) available to the practitioner under the “right” design decisions for setting up training. Scaling laws can then inform practitioners how to most reliably obtain performance at scale. For example, <a href="https://arxiv.org/abs/2203.03466" class="link" target="_blank" rel="external noopener noreferrer">prior</a> <a href="https://arxiv.org/abs/2001.08361" class="link" target="_blank" rel="external noopener noreferrer">work</a> establishes that it is possible to estimate the best batch size and model width and depth from small-scale runs, and leverages this predictability to predict the best configuration for an extrapolated model size. <em>Can we build similar workflows for reinforcement learning (RL) algorithms?</em> In this blog post, we explore whether we can derive scaling laws for online RL algorithms.</p>
<p>Our blog is based on a series of two papers that challenge the conventional wisdom that value-based off-policy RL methods are fundamentally unpredictable. As we discuss below, as long as we follow careful workflows to predict hyperparameters, <strong>value-based RL is predictable</strong>. That said, establishing scaling laws for off-policy RL is substantially harder than standard LLM training: while most scaling law studies assume a fixed data distribution, RL admits a moving data distribution and accumulation of previous data (”replay buffers”).</p>
<p><video class="block mx-auto autoplay-on-fullview md-video unselectable" aria-label="3D data efficiency plot" id="fig-3d-data-efficiency-plot" width="600px" muted playsinline playsinline data-freeze-ms="10000"><source src="/assets/images/h1stand_3d.mp4#t=0.1" type="video/mp4" /></video><div class='text-center text-gray-500 mb-4 md:px-8 lg:px-12 text-sm'><p><strong>Figure 1:</strong> We are able to estimate scaling laws for value-based RL. Data efficiency is predictable with respect to UTD and model size, unlocking compute-optimal scaling.</p>
</div></p>
<h2 id="part-i-challenges-of-estimating-scaling-laws-for-rl">Part I: Challenges of estimating scaling laws for RL</h2><p>Let’s start by attempting to understand the challenges we need to resolve to estimate scaling laws for RL. Scaling laws typically answer:</p>
<blockquote class="inline-block bg-neutral-50 border-l-4 border-neutral-600 rounded px-3 py-2 align-middle my-2"><p><em>Given a large, unseen budget on resources (i.e., data and compute for our study), how can we achieve the best possible performance?</em></p>
</blockquote><p>To make this question concrete, let’s work through the case of LLM pre-training. In LLM research, the budget corresponds to the total compute used for training, measured in FLOPs, and the performance metric is test perplexity. This budget can be further decomposed into a function of the model size, the dataset size, and hyperparameters (number of epochs and batch size): <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>compute</mtext><mo>∝</mo><mtext>dataset size</mtext><mo>×</mo><mtext>epochs</mtext><mo>×</mo><mtext>batch size</mtext><mo>×</mo><mtext>model size</mtext><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\text{compute} \propto \text{dataset size} \times \text{epochs} \times \text{batch size} \times \text{model size}.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8095em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord">compute</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∝</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord text"><span class="mord">dataset size</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord">epochs</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord text"><span class="mord">batch size</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">model size</span></span><span class="mord">.</span></span></span></span></span></p>
<p>Within this framework, researchers have arrived at conclusions on the optimal <a href="https://arxiv.org/abs/2305.16264" class="link" target="_blank" rel="external noopener noreferrer">data-epoch tradeoff</a>, the <a href="https://arxiv.org/abs/2001.08361" class="link" target="_blank" rel="external noopener noreferrer">data-model tradeoff</a>, and the <a href="https://arxiv.org/abs/1812.06162" class="link" target="_blank" rel="external noopener noreferrer">critical batch size</a>, together prescribing rules for setting hyperparameters and characterizing how performance metrics depend on available resources when hyperparameters are set accordingly. This enabled simple <a href="https://arxiv.org/abs/2001.08361" class="link" target="_blank" rel="external noopener noreferrer">power laws</a> forecasting the loss in terms of model size and dataset size. With the right batch size and epoch count, balancing between model size and dataset size laid the groundwork to train large models <a href="https://arxiv.org/abs/2203.15556" class="link" target="_blank" rel="external noopener noreferrer">compute-optimally</a>.</p>
<p>We follow a similar protocol for RL, though hyperparameters and performance metrics vary substantially between LLM pre-training and RL. We first describe how RL scaling laws are different, then dive into estimating them.</p>
<h2 id="what-makes-rl-scaling-laws-different">What makes RL scaling laws different?</h2><p>Let’s now make the scaling question concrete in the context of RL. While LLM pre-training assumes access to i.i.d. high-quality training data, in RL, data is collected by the learning algorithm itself, which means that data is now a resource. Indeed RL research often optimizes for sample-efficiency, in an attempt to maximize performance given a fixed number of samples. We will denote the resource of data as <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">D</mi></mrow><annotation encoding="application/x-tex">\mathcal D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span></span></span></span>. In addition, like pre-training, RL will spend FLOPs during training, which means compute <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">C</mi></mrow><annotation encoding="application/x-tex">\mathcal C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.05834em;">C</span></span></span></span></span> spent training on the data is still a resource. While compute <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">C</mi></mrow><annotation encoding="application/x-tex">\mathcal{C}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.05834em;">C</span></span></span></span></span> depends on data <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">D</mi></mrow><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span></span></span></span> for any ML procedure, online RL collects data “in-the-loop” by running intermediate policies online — meaning that the process of data collection itself spends additional time or GPU/CPU computation. Therefore, it is more beneficial to consider a more holistic notion of budget that combines <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">C</mi></mrow><annotation encoding="application/x-tex">\mathcal{C}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.05834em;">C</span></span></span></span></span> and <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">D</mi></mrow><annotation encoding="application/x-tex">\mathcal{D}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span></span></span></span>: <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">F</mi><mo>=</mo></mrow><annotation encoding="application/x-tex">\mathcal{F} =</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.09931em;">F</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span></span></span></span></span> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">C</mi><mo>+</mo><mi>δ</mi><mo>⋅</mo><mi mathvariant="script">D</mi></mrow><annotation encoding="application/x-tex">\mathcal C + \delta \cdot \mathcal D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span></span></span></span>, where <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span></span> is a domain-specific constant.</p>
<p>The performance metric is an agent’s performance, i.e. the average return attained by the agent. This setup gives us our problem statement:</p>
<blockquote class="inline-block bg-neutral-50 border-l-4 border-neutral-600 rounded px-3 py-2 align-middle my-2"><p><em>Given a limited budget</em> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">F</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\mathcal F_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.09931em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0993em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><em>, on a combination <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">F</mi><mo>=</mo><mi mathvariant="script">C</mi><mo>+</mo><mi>δ</mi><mo>⋅</mo><mi mathvariant="script">D</mi></mrow><annotation encoding="application/x-tex">\mathcal{F} = \mathcal C + \delta \cdot \mathcal D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.09931em;">F</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span></span></span></span> of compute and data, how do we achieve the best possible return</em> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>J</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">J^*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span><em>?</em></p>
</blockquote><p>In practice, this problem is hard to answer directly, since reward transformations can make return unpredictable without actually changing the optimal policy at all. Therefore, we’ll consider the dual problem. Define <strong>data efficiency</strong> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">D</mi><mi>J</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal D_J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> and <strong>compute efficiency</strong> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">C</mi><mi>J</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal C_J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0583em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> as the amounts of data and compute needed to achieve performance <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span></span></span></span></span>, respectively. Then, the best possible <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>J</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">J^*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span> that we can attain given the budget <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">F</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\mathcal{F}_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.09931em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0993em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> should be the one where we have used up exactly the allocated budget, i.e., <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">F</mi><mn>0</mn></msub><mo>=</mo><msub><mi mathvariant="script">C</mi><msup><mi>J</mi><mo>∗</mo></msup></msub><mo>+</mo><mi>δ</mi><mo>⋅</mo><msub><mi mathvariant="script">D</mi><msup><mi>J</mi><mo>∗</mo></msup></msub></mrow><annotation encoding="application/x-tex">\mathcal F_0 = \mathcal C_{J^*} + \delta \cdot \mathcal D_{J^*}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.09931em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0993em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0583em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6183em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6183em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>. So, we can instead estimate <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">D</mi><mi>J</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal D_J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> and <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">C</mi><mi>J</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal C_J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0583em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> for multiple <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span></span></span></span></span>, then select the largest <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span></span></span></span></span> fitting within the budget <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">F</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\mathcal{F}_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.09931em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0993em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>. This results in a different scaling question that we will study in this line of work:</p>
<blockquote class="inline-block bg-neutral-50 border-l-4 border-neutral-600 rounded px-3 py-2 align-middle my-2"><p><em>Given a performance threshold</em> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span></span></span></span></span>, <em>how can we allocate our resources to minimize the budget</em> ‍ <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">C</mi><mi>J</mi></msub><mo>+</mo><mi>δ</mi><mo>⋅</mo><msub><mi mathvariant="script">D</mi><mi>J</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal C_J + \delta \cdot \mathcal D_J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0583em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><em>?</em></p>
</blockquote><p>Scaling laws have been <a href="https://arxiv.org/abs/2301.13442" class="link" target="_blank" rel="external noopener noreferrer">studied</a> for <strong>on-policy algorithms</strong>, like <a href="https://arxiv.org/abs/1707.06347" class="link" target="_blank" rel="external noopener noreferrer">PPO</a> and <a href="https://arxiv.org/abs/2402.03300" class="link" target="_blank" rel="external noopener noreferrer">GRPO</a>. On-policy algorithms iteratively collect a batch of trajectories from the current policy <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span></span>, score those trajectories, and take a gradient step toward high-scoring trajectories (perhaps subject to constraints). At each iteration, once the update is done, the data must be thrown away, and a new batch is collected from the new policy. This highlights a data efficiency limitation: on-policy algorithms discard data, and is not optimal at minimizing budgets. Thus, we turn to off-policy RL, which can learn from data collected by policies other than <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span></span>. We briefly review off-policy RL.</p>
<h3 id="primer-on-off-policy-rl">Primer on off-policy RL</h3><p>Modern off-policy RL typically trains a <strong>value function</strong> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q_\theta(s,a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span></span>. The learned value function is agnostic to the policy used to collect state-action transitions (”behavior policy”) – instead, these transitions are sampled from a replay buffer <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">P</mi></mrow><annotation encoding="application/x-tex">\mathcal P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.08222em;">P</span></span></span></span></span> storing all past transitions. The Q-function then aims to estimate the expected reward under the learned policy. In practice, the Q-network is trained by regressing onto a <em>bootstrapped</em> target, called the <strong>temporal difference (TD)-target</strong> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><mover accent="true"><mi>Q</mi><mo>ˉ</mo></mover><mo stretchy="false">(</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">r(s,a) + \gamma \bar Q(s&#x27;, a&#x27;)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0701em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8201em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">Q</span></span><span style="top:-3.2523em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>, where <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>Q</mi><mo>ˉ</mo></mover></mrow><annotation encoding="application/x-tex">\bar Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0145em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8201em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">Q</span></span><span style="top:-3.2523em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span></span> comes from a stale copy of the Q-network, often called the target network. The regression loss, which is referred to as the <strong>temporal difference error (TD error)</strong> is given by:</p>
<div class="math math-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi mathvariant="double-struck">E</mi><mrow><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo separator="true">,</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo>∼</mo><mi mathvariant="script">P</mi><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>∼</mo><mi>π</mi><mo stretchy="false">(</mo><mo>⋅</mo><mi mathvariant="normal">∣</mi><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow></msub><mrow><mo fence="true">[</mo><msup><mrow><mo fence="true">(</mo><mi>r</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><mover accent="true"><mi>Q</mi><mo>ˉ</mo></mover><mo stretchy="false">(</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo>−</mo><msub><mi>Q</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo fence="true">)</mo></mrow><mn>2</mn></msup><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">L(\theta) = \mathbb{E}_{(s, a, s&#x27;) \sim \mathcal{P}, a&#x27; \sim \pi(\cdot|s&#x27;)}\left[ \left(r(s, a) + \gamma \bar{Q}(s&#x27;, a&#x27;) - Q_\theta(s, a) \right)^2\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">a</span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose mtight">)</span><span class="mrel mtight">∼</span><span class="mord mathcal mtight" style="margin-right:0.08222em;">P</span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mrel mtight">∼</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span><span class="mopen mtight">(</span><span class="mord mtight">⋅</span><span class="mord mtight">∣</span><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">[</span></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8201em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">Q</span></span><span style="top:-3.2523em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.054em;"><span style="top:-3.3029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">]</span></span></span></span></span></span></span></div><p>Regressing onto TD-targets introduces complexities that we need to account for when scaling:</p>
<ul>
<li>The TD-targets are moving because <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>Q</mi><mo>ˉ</mo></mover></mrow><annotation encoding="application/x-tex">\bar Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0145em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8201em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">Q</span></span><span style="top:-3.2523em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span></span> depends on <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span></span>.</li>
<li>Replay buffer introduces staleness because we revisit old data and train on it multiple times.</li>
</ul>
<p>However, this second mechanism is exactly what makes TD-learning compelling in data-limited regimes like robotic learning: we can reuse expensive experience many times. Intuitively, we can scale compute for a given amount of data by just taking multiple gradient steps on each batch sampled from the replay buffer. This can be quantified by a ratio: <strong>updates-to-data ratio (UTD)</strong>.</p>
<p>Going back, we can define the total compute utilized as follows:</p>
<div class="math math-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="script">C</mi><mi>J</mi></msub><mo>∝</mo><msub><mi mathvariant="script">D</mi><mi>J</mi></msub><mo>×</mo><mtext>UTD</mtext><mo>×</mo><mtext>batch size</mtext><mo>×</mo><mtext>model size</mtext></mrow><annotation encoding="application/x-tex">\mathcal C_J \propto \mathcal D_J  \times \text{UTD} \times \text{batch size} \times \text{model size}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0583em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∝</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord text"><span class="mord">UTD</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord text"><span class="mord">batch size</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">model size</span></span></span></span></span></span></div><p>This gives us multiple ways to control budget in RL: one approach is to <em>increase the UTD ratio</em>, training more on the same data while reducing the amount of new data collected; another is to <em>increase model size</em>, enabling better learning from the same data. A third approach is to use both small model size and UTD ratio, but collect more data. However, these configurations do not behave identically. For example, it is well known that increasing the UTD ratio improves performance at small values, but increasing it excessively can <a href="https://arxiv.org/abs/2205.07802" class="link" target="_blank" rel="external noopener noreferrer">degrade performance</a>, a form of “overfitting.” In repetitive, long-horizon tasks designed for scalability with horizon reduction, it was shown that scaling the model size led to <a href="https://seohong.me/blog/q-learning-is-not-yet-scalable/" class="link" target="_blank" rel="external noopener noreferrer">plateauing performance</a>. Likewise, while larger models can reduce the required amount of data <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">D</mi><mi>J</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal{D}_J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>, it is known that smaller models <a href="https://arxiv.org/abs/2211.15144" class="link" target="_blank" rel="external noopener noreferrer">can reduce</a> the required amount of compute <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">C</mi><mi>J</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal C_J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0583em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>.</p>
<p>Accordingly, we need to be quite careful when studying scaling laws for RL. Unlike pre-training, where models see each data point over a small number of epochs, off-policy RL repeatedly trains on the same data and is thus more prone to overfitting (see <a href="#why-is-overfitting-especially-problematic-in-value-based-rl" class="link">footnote</a>).
Nevertheless, the optimal budget-minimizing solution appears to require passing over the same data more than once, which raises the question of how to set hyperparameters in the presence of overfitting. Empirically, we find that choosing the correct batch size and learning rate mitigates overfitting in both cases and enables scaling to higher UTD ratios and model sizes, as we discuss next.</p>
<h2 id="part-ii-how-do-i-set-my-hyperparameters">Part II: How do I set my hyperparameters…</h2><p>A key ingredient enabling scaling laws for pre-training is the wide array of theoretical and practical results establishing the relationship between optimal <a href="https://www.jmlr.org/papers/v20/18-789.html" class="link" target="_blank" rel="external noopener noreferrer">batch size</a>, <a href="https://arxiv.org/abs/1404.5997" class="link" target="_blank" rel="external noopener noreferrer">learning rate</a>, and <a href="https://proceedings.neurips.cc/paper/2019/hash/e0eacd983971634327ae1819ea8b6214-Abstract.html" class="link" target="_blank" rel="external noopener noreferrer">optimizer</a>. Put together, these trends enable <a href="https://arxiv.org/abs/2203.03466" class="link" target="_blank" rel="external noopener noreferrer">hyperparameter transfer</a> to unseen model sizes.</p>
<p>In our answer to this question, we unlock several surprising findings on off-policy RL training dynamics, which we later leverage to scale UTD and model size effectively.</p>
<h3 id="when-i-scale-the-utd">…when I scale the UTD?</h3><!-- HTML_TAG_END --></div><a href="#utd_scaling" class="block -mx-4 mb-4 px-4 py-2 bg-gray-100 hover:bg-slate-100 rounded transition"><span class="text-neutral-500" data-svelte-h="svelte-a7fxhe">↪</span> Our paper: <em>Value-Based Deep RL Scales Predictably</em></a><div class="md-output svelte-2uty9x"><!-- HTML_TAG_START --><p>Let’s first look at the case of UTD-only scaling at a constant model size. Empirically, we find that performance is most sensitive to changes in batch size and learning rate, and we’ll focus on these hyperparameters.</p>
<p>Let’s first consider the effect of UTD scaling on the training data. For the purposes of this discussion, we define “overfitting” as the difference between TD errors on data sampled uniformly at random from the replay buffer <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">P</mi></mrow><annotation encoding="application/x-tex">\mathcal P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.08222em;">P</span></span></span></span></span> and the data most recently added to the replay buffer. Intuitively, high UTD and high batch size both see a typical sample more times and overfit to those samples. This results in higher relative TD error on data recently collected by the policy <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span></span>. We also observe the same empirically. <strong>To counteract this effect, we decrease the batch size for higher UTD.</strong></p>
<p><img src="/assets/images/overfitting_b.png" alt="Overfitting vs batch size" id="fig-overfitting-vs-batch-size" class="block mx-auto unselectable" width="600px" /><div class='text-center text-gray-500 mb-4 md:px-8 lg:px-12 text-sm'><p><strong>Figure 2:</strong> Overfitting increases with both UTD and batch size.</p>
</div></p>
<p>Next, let’s consider the effect of UTD scaling on Q-learning dynamics. Increasing the UTD aims to fit too well to the previous TD-target, making it more difficult to fit TD-targets later in training. Similarly, we observed that higher learning rates lead to high-magnitude updates against the target, moving the parameters to a state that would suffer from difficulty in fitting subsequent targets. Following prior work, we empirically find that one diagnosis for this plasticity loss is large parameter norm in the Q-network: increasing either UTD or learning rate corresponds to larger parameter norm. To counteract this effect, we decrease the learning rate for higher UTD.</p>
<p><img src="/assets/images/pnorm_lr.png" alt="Parameter norm vs learning rate" id="fig-parameter-norm-vs-learning-rate" class="block mx-auto unselectable" width="600px" /><div class='text-center text-gray-500 mb-4 md:px-8 lg:px-12 text-sm'><p><strong>Figure 3:</strong> Parameter norm, a proxy for plasticity loss, increases with both UTD and learning rate.</p>
</div></p>
<!-- HTML_TAG_END --></div><div class="my-4 rounded bg-slate-50 hover:bg-sky-50/50 p-4 pb-1 border-l-4 border-sky-700 transition"><div class="text-xs font-semibold tracking-wide uppercase text-sky-700" data-svelte-h="svelte-8vdxxn">Takeaways</div> <div class="prose max-w-none mt-1"><div class="md-output"><!-- HTML_TAG_START --><p>The best-choice batch size and learning rate are predictable functions of the UTD ratio,
and both decay as power laws.</p>
<!-- HTML_TAG_END --></div></div></div><div class="md-output svelte-2uty9x"><!-- HTML_TAG_START --><!-- ``` -->

<h3 id="when-i-scale-the-model-size">…when I scale the model size?</h3><!-- HTML_TAG_END --></div><a href="#model_scaling" class="block -mx-4 mb-4 px-4 py-2 bg-gray-100 hover:bg-slate-100 rounded transition"><span class="text-neutral-500" data-svelte-h="svelte-a7fxhe">↪</span> Our paper: <em>Compute-Optimal Scaling for Value-Based Deep RL</em></a><div class="md-output svelte-2uty9x"><!-- HTML_TAG_START --><p>Let’s now look at the case of model size scaling at a constant UTD. Generally, larger models are better performant, but it is unclear how one should set other hyperparameters when model size is increased. Model size scaling is a complementary approach to scaling compute which does not require taking multiple updates on the same data, so we’ll instead directly measure the Q-network’s generalization capabilities. To do so, we measure the TD error on both the training data and a held-out validation set of transitions drawn from a replay buffer with the same distribution.</p>
<p><video class="block mx-auto autoplay-on-fullview md-video unselectable" aria-label="TD-overfitting example" id="fig-td-overfitting-example" width="600px" muted playsinline playsinline data-freeze-ms="10000"><source src="/assets/images/loss2x2_crawl.mp4#t=0.1" type="video/mp4" /></video><div class='text-center text-gray-500 mb-4 md:px-8 lg:px-12 text-sm'><p><strong>Figure 4:</strong> Training and validation TD-errors reduce as model size increase. However, for smaller models, a larger batch size results in a higher final TD-error. This illustrates the role of batch size in modulating overfitting with TD-learning.</p>
</div></p>
<p>Unsurprisingly, increasing the batch size improves training TD-error. However, the effect on validation TD-error is more nuanced and depends on the model size. Why does this happen?</p>
<p>We find that small Q-nets produce TD-targets that generalize poorly, which is exacerbated by larger batch sizes. Larger Q-networks produce better TD-targets and can benefit from large batch sizes. We encourage you to check out our understanding of this phenomenon, which we coin <strong>TD-overfitting</strong>, in the <a href="#deep-dive-how-does-overfitting-manifest-with-model-size-scaling" class="link">deep dive</a> below.</p>
<p><strong>So, how do I set my batch size?</strong> Empirically, we observe that the best batch size increases with model size, but eventually reaches an upward asymptote. Check out <a href="https://arxiv.org/abs/2508.14881" class="link" target="_blank" rel="external noopener noreferrer">our new paper</a> for our fit equation! Empirically we do not observe a significant interaction effect between UTD and model size, i.e. our fit factorizes into a power law decay in UTD and an upward asymptote in model size.</p>
<p><strong>How about other key hyperparameters?</strong> In <a href="https://arxiv.org/abs/2508.14881" class="link" target="_blank" rel="external noopener noreferrer">our new paper</a>, we additionally consider the effect of learning rate (Appendix D.2) and the target update rate (Appendix D.3). For “reasonable” selections of those hyperparameters, we found that data efficiency was most sensitive to changes in batch size. These hyperparameters still depend on the UTD ratio, but they are less sensitive to model size alone.</p>
<!-- HTML_TAG_END --></div><div class="my-4 rounded bg-slate-50 hover:bg-sky-50/50 p-4 pb-1 border-l-4 border-sky-700 transition"><div class="text-xs font-semibold tracking-wide uppercase text-sky-700" data-svelte-h="svelte-8vdxxn">Takeaways</div> <div class="prose max-w-none mt-1"><div class="md-output"><!-- HTML_TAG_START --><ul>
<li><strong>TD-overfitting</strong>: Overfitting is a result of poor generalization of TD-targets from smaller models.</li>
<li>With low model capacity, increasing batch size results in a higher validation TD-error;
with high model capacity, increasing batch size results in a lower validation TD-error.</li>
<li>The best batch size increases with model size and decreases with the UTD ratio.</li>
</ul>
<!-- HTML_TAG_END --></div></div></div><div class="md-output svelte-2uty9x"><!-- HTML_TAG_START --><h2 id="part-iiia-budget-optimal-scaling-for-off-policy-rl">Part IIIa: Budget-optimal scaling for off-policy RL</h2><!-- HTML_TAG_END --></div><a href="#utd_scaling" class="block -mx-4 mb-4 px-4 py-2 bg-gray-100 hover:bg-slate-100 rounded transition"><span class="text-neutral-500" data-svelte-h="svelte-a7fxhe">↪</span> Our paper: <em>Value-Based Deep RL Scales Predictably</em></a><div class="md-output svelte-2uty9x"><!-- HTML_TAG_START --><p>With the design of hyperparameters above, we now attempt to put together scaling laws as a function of the total budget given to us. As before, we’ll first consider UTD-only scaling at a constant model size. Armed with the best-choice batch size and learning rate, we can optimize the data efficiency. Empirically, we find that data efficiency scales as a power law with respect to UTD, across multiple domains, tasks, and algorithms!</p>
<p><img src="/assets/images/hparam_asymptotic.png" alt="Data efficiency vs UTD" id="fig-data-efficiency-vs-utd" class="block mx-auto unselectable" width="400px" /><div class='text-center text-gray-500 mb-4 md:px-8 lg:px-12 text-sm'><p><strong>Figure 5:</strong> Data efficiency scales as a power law with respect to UTD. Leveraging the batch size and learning rate fits asymptotically outperforms a constant baseline.</p>
</div></p>
<p>Finally, we are in a position to answer our question:</p>
<blockquote class="inline-block bg-neutral-50 border-l-4 border-neutral-600 rounded px-3 py-2 align-middle my-2"><p><em>Given a performance threshold</em> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span></span></span></span></span>, <em>what is the minimum achievable budget</em> ‍ <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">C</mi><mi>J</mi></msub><mo>+</mo><mi>δ</mi><mo>⋅</mo><msub><mi mathvariant="script">D</mi><mi>J</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal C_J + \delta \cdot \mathcal D_J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0583em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>, where the <strong>data efficiency</strong> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">D</mi><mi>J</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal D_J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> and <strong>compute efficiency</strong> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">C</mi><mi>J</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal C_J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0583em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> <em>are the amounts of data and compute spent to achieve performance</em> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span></span></span></span></span><em>?</em></p>
</blockquote><p>We can consider the amount of compute, in FLOPs, required to achieve a given performance threshold. For each performance threshold, there is a Pareto frontier defining the tradeoff between data and compute requirements, and the UTD defines the position along this curve. Along this Pareto frontier, there is a unique budget-minimizing choice of UTD. In our paper, we showed that the budget-optimal partition between data and compute is predictable, as well as the budget-optimal UTD itself!</p>
<p>This tradeoff is predictable across multiple domains and algorithms. Moreover, the budget-optimal UTD extrapolates well to larger budgets! <strong>Our scaling laws let you predict the best data-compute tradeoff, parametrized by the UTD, at unseen budgets.</strong></p>
<p><video class="block mx-auto autoplay-on-fullview md-video unselectable" aria-label="UTD scaling summary" id="fig-utd-scaling-summary" width="600px" muted playsinline playsinline data-freeze-ms="10000"><source src="/assets/images/utd_scaling_summary.mp4#t=0.1" type="video/mp4" /></video><div class='text-center text-gray-500 mb-4 md:px-8 lg:px-12 text-sm'><p><strong>Figure 6:</strong> Each contour is the curve attaining the same fitted data efficiency to achieve a given target performance <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span></span></span></span></span>. The budget-optimal UTD and model size are marked with stars.</p>
</div></p>
<!-- HTML_TAG_END --></div><div class="my-4 rounded bg-slate-50 hover:bg-sky-50/50 p-4 pb-1 border-l-4 border-sky-700 transition"><div class="text-xs font-semibold tracking-wide uppercase text-sky-700" data-svelte-h="svelte-8vdxxn">Takeaways</div> <div class="prose max-w-none mt-1"><div class="md-output"><!-- HTML_TAG_START --><ul>
<li>Leveraging the best batch size and learning rate, the data efficiency decreases as
a power-law in the UTD ratio.</li>
<li>For each threshold, the UTD defines a Pareto frontier between data and compute
requirements.</li>
<li>The budget-optimal UTD is predictable, following a power law that can extrapolate to
large budgets.</li>
</ul>
<!-- HTML_TAG_END --></div></div></div><div class="md-output svelte-2uty9x"><!-- HTML_TAG_START --><h2 id="part-iiib-budget-optimal-scaling-for-utd-and-model-size">Part IIIb: Budget-optimal scaling for UTD and model size</h2><!-- HTML_TAG_END --></div><a href="#model_scaling" class="block -mx-4 mb-4 px-4 py-2 bg-gray-100 hover:bg-slate-100 rounded transition"><span class="text-neutral-500" data-svelte-h="svelte-a7fxhe">↪</span> Our paper: <em>Compute-Optimal Scaling for Value-Based Deep RL</em></a><div class="md-output svelte-2uty9x"><!-- HTML_TAG_START --><p>Now, we’ll additionally leverage incorporate model size into our fit. To do so, we will use our knowledge of the TD-overfitting phenomenon (see <a href="#deep-dive-how-does-overfitting-manifest-with-model-size-scaling" class="link">deep dive</a>), which prescribes how batch sizes must be set when model size is changed. Long story short, we find that data efficiency scales as a sum of power laws with respect to the UTD and model size. (In Section 6 of our new paper, we also run a sensitivity analysis to show the importance of using the right batch size.)</p>
<p><video class="block mx-auto autoplay-on-fullview md-video unselectable" aria-label="Data iso contours" id="fig-data-iso-contours" width="600px" muted playsinline playsinline data-freeze-ms="10000"><source src="/assets/images/data_iso_contour.mp4#t=0.1" type="video/mp4" /></video><div class='text-center text-gray-500 mb-4 md:px-8 lg:px-12 text-sm'><p><strong>Figure 7:</strong> Each contour is the curve attaining the same fitted data efficiency to achieve a given target performance <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span></span></span></span></span>. The budget-optimal UTD and model size are marked with stars.</p>
</div></p>
<p>Conveniently, our fit equation admits a closed-form solution for budget-optimal UTD and model size, in terms of the data efficiency! We find that, within a given budget, UTD-only scaling and model-size–only scaling use 11% and 26% more data, respectively, compared to the compute-optimal setting. In the paper, we similarly show that the data–compute partition is predictable at extrapolated budgets – check it out!</p>
<!-- HTML_TAG_END --></div><div class="my-4 rounded bg-slate-50 hover:bg-sky-50/50 p-4 pb-1 border-l-4 border-sky-700 transition"><div class="text-xs font-semibold tracking-wide uppercase text-sky-700" data-svelte-h="svelte-8vdxxn">Takeaways</div> <div class="prose max-w-none mt-1"><div class="md-output"><!-- HTML_TAG_START --><ul>
<li>Leveraging the best batch size, data efficiency can be modeled as a sum of power laws
decaying in UTD and model size.</li>
<li>Our fits tell you whether it is more compute-efficient to scale your UTD or model size.</li>
</ul>
<!-- HTML_TAG_END --></div></div></div><div class="md-output svelte-2uty9x"><!-- HTML_TAG_START --><h2 id="a-call-for-scalable-rl-algorithms">A call for scalable RL algorithms</h2><p>Scaling laws provide a blueprint for building RL methods that scales. By identifying the scalable regime, we show that value-based RL admits predictable scaling once its core instabilities, which manifests as overfitting, are resolved. In pre-training, scaling laws depend on the best choice of model size, batch size, and learning rate. In value-based RL, these relationships are much trickier to uncover, due to data distribution shift and the use of target networks in practice. These training dynamics are associated with a suite of parameters including the replay buffer size, optimizer, loss function (here, a distributional RL critic), and actor update frequency. Each new axis adds to the foundation for compute-optimal training, and scaling law research can extend to new parameters and training regimes.</p>
<p>Ultimately, though, we must not only characterize existing methods, but also design better algorithms. We urge the field to provide systematic scalability studies:</p>
<p><strong>Step 1:</strong> Characterize scaling in existing algorithms.</p>
<p><strong>Step 2:</strong> Use scaling laws to select the best-performing methods.</p>
<p><strong>Step 3:</strong> Design new algorithms that scale more reliably across domains and budgets.</p>
<p>The goal is not just to show that RL <em>can</em> scale, but to establish a framework where scaling laws <em>guide the design</em> of the next generation of scalable RL techniques. We believe this direction is key to unlocking value-based RL for larger-scale practical applications, such as LLM agents.</p>
<br>

<hr>
<br>

<h2 id="deep-dive-how-does-overfitting-manifest-with-model-size-scaling">Deep dive: how does overfitting manifest with model size scaling?</h2><p>In <a href="#fig-td-overfitting-example" class="link">Figure 4</a>, we observed that for small models, larger batch sizes worsened generalization; for large models, larger batch sizes helped. (See Appendix B of <a href="https://arxiv.org/abs/2508.14881" class="link" target="_blank" rel="external noopener noreferrer">our new paper</a> for more details on constructing the validation dataset). It’s helpful to look at these curves over the course of training, since in the practical implementation of TD-learning, value functions rarely fully fit the moving TD-targets.</p>
<p><strong>Conceptual view:</strong> We argue that this deviation from classical overfitting is explained by the use of target networks in TD-learning, and coin this phenomenon <strong>TD-overfitting</strong>. Consider a smaller value function. Due to its low representational capacity, a model would entangle features used for predicting Q-values across multiple (state, action) pairs. As we scale up the batch size, this issue is exacerbated since these incorrect gradient updates become more “directed”. Fitting the Q-function, and hence the TD-targets, on some transitions comes at the expense of others.</p>
<p>By contrast, larger value functions produce features that can decouple its predictions across transitions, leading to improved generalization at larger batch sizes.</p>
<p><img src="/assets/images/td_overfitting_concept.png" alt="TD-overfitting concept" id="fig-td-overfitting-concept" class="block mx-auto unselectable" width="600px" /><div class='text-center text-gray-500 mb-4 md:px-8 lg:px-12 text-sm'><p><strong>Figure 8:</strong> Small models perform better with smaller batch sizes, which result in noisy updates, due to more directed gradient updates onto low-quality TD-targets. Larger models produce higher-quality TD targets and benefit from regressing to these targets better with larger batch sizes.</p>
</div></p>
<p>Check out <a href="https://arxiv.org/abs/2508.14881" class="link" target="_blank" rel="external noopener noreferrer">our new paper</a> (Section 5.3) for an empirical analysis of this phenomenon! Or go back to the <a href="#when-i-scale-the-model-size" class="link">model scaling section</a>.</p>
<h2 id="why-is-overfitting-especially-problematic-in-value-based-rl">Why is overfitting especially problematic in value-based RL?</h2><p>Language model research has shown that training on the same data more than <a href="https://arxiv.org/abs/2305.16264" class="link" target="_blank" rel="external noopener noreferrer">4 times</a> yields diminishing returns. For contrast, we can compute this number in off-policy RL training. In simulated robotic tasks, we typically “seed” a replay buffer with <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">D</mi><mn>0</mn></msub><mi mathvariant="normal">∣</mi><mo>≈</mo><mn>5</mn><mtext>e</mtext><mn>3</mn></mrow><annotation encoding="application/x-tex">|\mathcal D_0| \approx 5\text e3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">5</span><span class="mord text"><span class="mord">e</span></span><span class="mord">3</span></span></span></span></span> transitions, use a batch size <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>≈</mo><mn>512</mn></mrow><annotation encoding="application/x-tex">B \approx 512</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">512</span></span></span></span></span>, and train for up to <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">D</mi><mn>1</mn></msub><mi mathvariant="normal">∣</mi><mo>≈</mo><mn>1</mn><mtext>e</mtext><mn>6</mn></mrow><annotation encoding="application/x-tex">|\mathcal D_1| \approx 1\text e6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span><span class="mord text"><span class="mord">e</span></span><span class="mord">6</span></span></span></span></span> transitions. By linearity of expectation, the <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span>th element in the replay buffer is expected to be sampled in</p>
<div class="math math-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>B</mi><mrow><mo fence="true">(</mo><mfrac><mn>1</mn><mrow><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">D</mi><mn>0</mn></msub><mi mathvariant="normal">∣</mi><mo>+</mo><mn>1</mn></mrow></mfrac><mo>+</mo><mfrac><mn>1</mn><mrow><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">D</mi><mn>0</mn></msub><mi mathvariant="normal">∣</mi><mo>+</mo><mn>2</mn></mrow></mfrac><mo>+</mo><mo>⋯</mo><mo>+</mo><mfrac><mn>1</mn><mrow><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">D</mi><mn>1</mn></msub><mi mathvariant="normal">∣</mi></mrow></mfrac><mo fence="true">)</mo></mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>i</mi><mo>≤</mo><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">D</mi><mn>0</mn></msub><mi mathvariant="normal">∣</mi><mo>+</mo><mn>1</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>B</mi><mrow><mo fence="true">(</mo><mfrac><mn>1</mn><mi>i</mi></mfrac><mo>+</mo><mfrac><mn>1</mn><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></mfrac><mo>+</mo><mo>⋯</mo><mo>+</mo><mfrac><mn>1</mn><mrow><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">D</mi><mn>1</mn></msub><mi mathvariant="normal">∣</mi></mrow></mfrac><mo fence="true">)</mo></mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>i</mi><mo>&gt;</mo><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">D</mi><mn>0</mn></msub><mi mathvariant="normal">∣</mi><mo>+</mo><mn>1</mn></mrow></mstyle></mtd></mtr></mtable></mrow><annotation encoding="application/x-tex">\begin{cases} B \left( \frac 1{|\mathcal D_0| + 1} + \frac 1{|\mathcal D_0| + 2} + \cdots + \frac 1{|\mathcal D_1|} \right) &amp; i \le |\mathcal D_0| + 1 \\ B \left( \frac 1{i} + \frac 1{i+1} + \cdots + \frac 1{|\mathcal D_1|} \right) &amp; i &gt; |\mathcal D_0| + 1 \end{cases}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.6em;vertical-align:-1.55em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-2.5em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎩</span></span></span><span style="top:-2.492em;"><span class="pstrut" style="height:3.15em;"></span><span style="height:0.016em;width:0.8889em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.8889em" height="0.016em" style="width:0.8889em" viewBox="0 0 888.89 16" preserveAspectRatio="xMinYMin"><path d="M384 0 H504 V16 H384z M384 0 H504 V16 H384z"/></svg></span></span><span style="top:-3.15em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎨</span></span></span><span style="top:-4.292em;"><span class="pstrut" style="height:3.15em;"></span><span style="height:0.016em;width:0.8889em;"><svg xmlns="http://www.w3.org/2000/svg" width="0.8889em" height="0.016em" style="width:0.8889em" viewBox="0 0 888.89 16" preserveAspectRatio="xMinYMin"><path d="M384 0 H504 V16 H384z M384 0 H504 V16 H384z"/></svg></span></span><span style="top:-4.3em;"><span class="pstrut" style="height:3.15em;"></span><span class="delimsizinginner delim-size4"><span>⎧</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.05em;"><span class="pstrut" style="height:3.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0278em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mord mtight">∣</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0278em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mord mtight">∣</span><span class="mbin mtight">+</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0278em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mord mtight">∣</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0278em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mord mtight">∣</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em;"><span style="top:-4.05em;"><span class="pstrut" style="height:3.15em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">∣</span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.15em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">∣</span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em;"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></div><p>training iterations (assuming sampling with replacement; we approximate since the replay buffer is typically much larger than the batch size). For the <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>≤</mo><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">D</mi><mn>0</mn></msub><mi mathvariant="normal">∣</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">i \le |\mathcal D_0| + 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7955em;vertical-align:-0.136em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span></span> case, we can approximate this as <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo stretchy="false">(</mo><mi>ln</mi><mo>⁡</mo><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">D</mi><mn>1</mn></msub><mi mathvariant="normal">∣</mi><mo>−</mo><mi>ln</mi><mo>⁡</mo><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">D</mi><mn>0</mn></msub><mi mathvariant="normal">∣</mi><mo stretchy="false">)</mo><mo>≈</mo><mn>2700</mn></mrow><annotation encoding="application/x-tex">B(\ln |\mathcal D_1| - \ln |\mathcal D_0|) \approx 2700</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mopen">(</span><span class="mop">ln</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">∣</span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">ln</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">∣</span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">2700</span></span></span></span></span>, i.e. the initial “seed” data is trained on around 2700 times. It is this orders-of-magnitude difference that explains the importance of studying overfitting in off-policy RL training.</p>
<p>Link back to our primer on <a href="#primer-on-off-policy-rl" class="link">off-policy RL</a>.</p>
<h2 id="acknowledgments">Acknowledgments</h2><p>We would like to thank <a href="https://zhouzypaul.github.io/" class="link" target="_blank" rel="external noopener noreferrer">Zhiyuan Zhou</a> for his helpful feedback
on this post. The views in this blog are our own and do not necessarily reflect those of our coauthors.</p>
<h2 id="citation">Citation</h2><pre><code class="language-bibtex">@article{fu2025scaling,
  title = {Scaling Laws for Value-Based RL},
  author = {Fu, Preston and Rybkin, Oleh and Kumar, Aviral},
  journal = {value-scaling.github.io},
  year = {2025},
  month = {September},
  url = &quot;https://value-scaling.github.io/&quot;
}
</code></pre>
<h2 id="references">References</h2><!-- HTML_TAG_END --></div><div class="md-output text-sm sm-block svelte-2uty9x"><!-- HTML_TAG_START --><p>Hilton et al. <em>Scaling laws for single-agent reinforcement learning</em>. arXiv, 2023.</p>
<p>Hoffmann et al. <em>Training compute-optimal large language models</em>. NeurIPS, 2023.</p>
<p>Kaplan et al. <em>Scaling laws for neural language models</em>. arXiv, 2020.</p>
<p>Krizhevsky. <em>One weird trick for parallelizing convolutional neural networks</em>. arXiv, 2014.</p>
<p>Kumar et al. <em>Offline Q-Learning on Diverse Multi-Task Data Both Scales And Generalizes</em>. ICLR, 2023.</p>
<p>McCandlish et al. <em>An empirical model of large-batch training</em>. arXiv, 2018.</p>
<p>Muennighoff et al. <em>Scaling data-constrained language models</em>. NeurIPS, 2023.</p>
<p>Nikishin et al. <em>The primacy bias in deep reinforcement learning</em>. ICML, 2022.</p>
<p>Park. <em>Q-learning is not yet scalable</em>. 2025.</p>
<p>Schulman et al. <em>Proximal Policy Optimization Algorithms</em>. arXiv, 2017.</p>
<p>Shallue et al. <em>Measuring the effects of data parallelism on neural network training</em>. JMLR, 2019.</p>
<p>Shao et al. <em>DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models</em>. arXiv, 2024.</p>
<p>Yang et al. <em>Tensor programs V: Tuning large neural networks via zero-shot hyperparameter transfer</em>. NeurIPS, 2021.</p>
<p>Zhang et al. <em>Which algorithmic choices matter at which batch sizes?</em> NeurIPS, 2019.</p>
<!-- HTML_TAG_END --></div><div class="md-output svelte-2uty9x"><!-- HTML_TAG_START --><!-- HTML_TAG_END --></div> </div></div> </div></main>  
			
			<script>
				{
					__sveltekit_1fvhh13 = {
						base: new URL(".", location).pathname.slice(0, -1)
					};

					const element = document.currentScript.parentElement;

					const data = [null,null];

					Promise.all([
						import("./_app/immutable/entry/start.NpdkYoDT.js"),
						import("./_app/immutable/entry/app.s2HBLhOM.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 2],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
  </body>
</html>
