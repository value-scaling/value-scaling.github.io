<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link
      rel="preload"
      href="./fonts/ibm_plex_sans/IBMPlexSans-Regular.ttf"
      as="font"
      type="font/ttf"
      crossorigin
    />
    <link
      rel="preload"
      href="./fonts/newsreader/Newsreader_14pt-Italic.ttf"
      as="font"
      type="font/ttf"
      crossorigin
    />
    <link rel="icon" href="./favicon.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    
		<link href="./_app/immutable/assets/0.Dq2gY4kV.css" rel="stylesheet">
		<link href="./_app/immutable/assets/2.vA80lXTd.css" rel="stylesheet">
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_AMS-Regular.BQhdFMY1.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_AMS-Regular.DMm9YOAa.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_AMS-Regular.DRggAlZN.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Caligraphic-Bold.Dq_IR9rO.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Caligraphic-Bold.BEiXGLvX.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Caligraphic-Bold.ATXxdsX0.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Caligraphic-Regular.Di6jR-x-.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Caligraphic-Regular.CTRA-rTL.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Caligraphic-Regular.wX97UBjC.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Fraktur-Bold.CL6g_b3V.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Fraktur-Bold.BsDP51OF.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Fraktur-Bold.BdnERNNW.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Fraktur-Regular.CTYiF6lA.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Fraktur-Regular.Dxdc4cR9.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Fraktur-Regular.CB_wures.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Main-Bold.Cx986IdX.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Main-Bold.Jm3AIy58.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Main-Bold.waoOVXN0.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Main-BoldItalic.DxDJ3AOS.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Main-BoldItalic.SpSLRI95.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Main-BoldItalic.DzxPMmG6.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Main-Italic.NWA7e6Wa.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Main-Italic.BMLOBm91.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Main-Italic.3WenGoN9.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Main-Regular.B22Nviop.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Main-Regular.Dr94JaBh.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Main-Regular.ypZvNtVU.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Math-BoldItalic.CZnvNsCZ.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Math-BoldItalic.iY-2wyZ7.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Math-BoldItalic.B3XSjfu4.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Math-Italic.t53AETM-.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Math-Italic.DA0__PXp.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Math-Italic.flOr_0UB.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_SansSerif-Bold.D1sUS0GD.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_SansSerif-Bold.DbIhKOiC.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_SansSerif-Bold.CFMepnvq.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_SansSerif-Italic.C3H0VqGB.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_SansSerif-Italic.DN2j7dab.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_SansSerif-Italic.YYjJ1zSn.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_SansSerif-Regular.DDBCnlJ7.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_SansSerif-Regular.CS6fqUqJ.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_SansSerif-Regular.BNo7hRIc.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Script-Regular.D3wIWfF6.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Script-Regular.D5yQViql.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Script-Regular.C5JkGWo-.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Size1-Regular.mCD8mA8B.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Size1-Regular.C195tn64.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Size1-Regular.Dbsnue_I.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Size2-Regular.Dy4dx90m.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Size2-Regular.oD1tc_U0.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Size2-Regular.B7gKUWhC.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Size3-Regular.CTq5MqoE.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Size3-Regular.DgpXs0kz.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Size4-Regular.Dl5lxZxV.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Size4-Regular.BF-4gkZK.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Size4-Regular.DWFBv043.ttf" crossorigin>
		<link rel="preload" as="font" type="font/woff2" href="./_app/immutable/assets/KaTeX_Typewriter-Regular.CO6r4hn1.woff2" crossorigin>
		<link rel="preload" as="font" type="font/woff" href="./_app/immutable/assets/KaTeX_Typewriter-Regular.C0xS9mPB.woff" crossorigin>
		<link rel="preload" as="font" type="font/ttf" href="./_app/immutable/assets/KaTeX_Typewriter-Regular.D3Ib7_Hf.ttf" crossorigin>
		<link rel="modulepreload" href="./_app/immutable/entry/start.DQ-iithN.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/entry.B6mrhB-L.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/scheduler.CGTIQush.js">
		<link rel="modulepreload" href="./_app/immutable/entry/app.DEWgKYMy.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/index.BzyyWbX-.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/0.BpV8XQ7j.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/stores.D0_g0y_x.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/2.9jFAFUiv.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/each.BXdS67XN.js"><title>Value-Based RL Scales</title><!-- HEAD_svelte-1r9of7h_START --><!-- HEAD_svelte-1r9of7h_END --><!-- HEAD_svelte-1u7ey3_START --><meta name="description" content="A project by UC Berkeley, CMU, and friends."><meta property="og:title" content="Value-Based RL Scales"><meta property="og:description" content="A project by UC Berkeley, CMU, and friends."><!-- HEAD_svelte-1u7ey3_END -->
  </head>
  <body data-sveltekit-preload-data="hover">
    <div style="display: contents">   <header class="layout-md flex justify-between items-start" data-sveltekit-noscroll data-sveltekit-preload-code="eager"><div class="mb-8 unselectable"><div class="flex items-center"><h1 class="font-bold text-black text-3xl">Scaling Laws for Value-Based RL
        </h1></div></div>  </header> <main>  <div> <div class="scroll-meter svelte-k31mcc" aria-hidden="true"><div class="track svelte-k31mcc"><div class="gradient svelte-k31mcc" style=""></div> </div> </div> <div class="layout-md text-lg space-y-12"><div class="space-y-2"><section id="model_scaling" class="svelte-1w2o5k5"> <div role="group" class="block -mx-4 mb-4 px-4 py-4 transition-colors unselectable hover:bg-sky-50 bg-sky-50"><div class="grid grid-cols-4 gap-4"> <div class="col-span-4 md:col-span-1"><div class="relative w-full max-w-80 mx-auto"><img src="/assets/images/model_scaling_before.png" alt="Compute-Optimal Scaling for Value-Based Deep RL preview image" class="w-full block"> <video class="absolute inset-0 w-full h-full object-cover pointer-events-none" style="opacity: 0; transition: opacity 160ms ease;" preload="metadata" muted loop playsinline aria-hidden="true" tabindex="-1" poster="/assets/images/model_scaling_before.png"><source src="/assets/images/model_scaling_3d.mp4" type="video/mp4"></video></div></div> <div class="col-span-4 md:col-span-3"><h3 class="text-black text-lg font-semibold mb-2 no-meter"><a class="link-no-underline mr-1" href="https://arxiv.org/abs/2508.14881" target="_blank">Compute-Optimal Scaling for Value-Based Deep RL</a> <small class="whitespace-nowrap text-neutral-500 text-base font-normal">July 2025</small></h3> <div class="text-sm reduced-spacing"><div class="md-output space-y-6 svelte-1kj7go7"><div class="md-output svelte-1kj7go7"><!-- HTML_TAG_START --><p><a href="https://www.prestonfu.com/" class="link" target="_blank" rel="external noopener noreferrer">Preston Fu</a>*,
<a href="https://olehrybkin.com/" class="link" target="_blank" rel="external noopener noreferrer">Oleh Rybkin</a>*,
<a href="https://zhouzypaul.github.io/" class="link" target="_blank" rel="external noopener noreferrer">Zhiyuan Zhou</a>,
<a href="https://scholar.google.com/citations?user=GnEVRtQAAAAJ&hl=en" class="link" target="_blank" rel="external noopener noreferrer">Michal Nauman</a>,
<a href="https://people.eecs.berkeley.edu/~pabbeel/" class="link" target="_blank" rel="external noopener noreferrer">Pieter Abbeel</a>,
<a href="https://people.eecs.berkeley.edu/~svlevine/" class="link" target="_blank" rel="external noopener noreferrer">Sergey Levine</a>,
<a href="https://aviralkumar2907.github.io/" class="link" target="_blank" rel="external noopener noreferrer">Aviral Kumar</a></p>
<p>Preprint</p>
<!-- HTML_TAG_END --></div> </div></div> <div class="flex flex-wrap gap-2"><a href="https://arxiv.org/abs/2508.14881" target="_blank" class="px-2 py-1 bg-sky-700 text-white text-[0.9rem] leading-[1rem] rounded hover:bg-sky-800 transition">arXiv </a><a href="https://github.com/prestonfu/model_scaling" target="_blank" class="px-2 py-1 bg-sky-700 text-white text-[0.9rem] leading-[1rem] rounded hover:bg-sky-800 transition">Code </a><a href="https://x.com/preston_fu/status/1962920781387882841" target="_blank" class="px-2 py-1 bg-sky-700 text-white text-[0.9rem] leading-[1rem] rounded hover:bg-sky-800 transition">Thread </a></div></div></div>  </div>  </section><section id="utd_scaling" class="svelte-1w2o5k5"> <div role="group" class="block -mx-4 mb-4 px-4 py-4 transition-colors unselectable hover:bg-sky-50 bg-sky-50"><div class="grid grid-cols-4 gap-4"> <div class="col-span-4 md:col-span-1"><div class="relative w-full max-w-80 mx-auto"><img src="/assets/images/qscaled_before.png" alt="Value-Based Deep RL Scales Predictably preview image" class="w-full block"> </div></div> <div class="col-span-4 md:col-span-3"><h3 class="text-black text-lg font-semibold mb-2 no-meter"><a class="link-no-underline mr-1" href="https://arxiv.org/abs/2502.04327" target="_blank">Value-Based Deep RL Scales Predictably</a> <small class="whitespace-nowrap text-neutral-500 text-base font-normal">February 2025</small></h3> <div class="text-sm reduced-spacing"><div class="md-output space-y-6 svelte-1kj7go7"><div class="md-output svelte-1kj7go7"><!-- HTML_TAG_START --><p><a href="https://olehrybkin.com/" class="link" target="_blank" rel="external noopener noreferrer">Oleh Rybkin</a>,
<a href="https://scholar.google.com/citations?user=GnEVRtQAAAAJ&hl=en" class="link" target="_blank" rel="external noopener noreferrer">Michal Nauman</a>,
<a href="https://www.prestonfu.com/" class="link" target="_blank" rel="external noopener noreferrer">Preston Fu</a>,
<a href="https://sea-snell.github.io/" class="link" target="_blank" rel="external noopener noreferrer">Charlie Snell</a>,
<a href="https://people.eecs.berkeley.edu/~pabbeel/" class="link" target="_blank" rel="external noopener noreferrer">Pieter Abbeel</a>,
<a href="https://people.eecs.berkeley.edu/~svlevine/" class="link" target="_blank" rel="external noopener noreferrer">Sergey Levine</a>,
<a href="https://aviralkumar2907.github.io/" class="link" target="_blank" rel="external noopener noreferrer">Aviral Kumar</a></p>
<p><em>International Conference on Machine Learning (ICML)</em>, 2025 <br><em>ICLR Robot Learning Workshop</em>, 2025 (<strong>oral presentation</strong>)</p>
<!-- HTML_TAG_END --></div> </div></div> <div class="flex flex-wrap gap-2"><a href="https://arxiv.org/abs/2502.04327" target="_blank" class="px-2 py-1 bg-sky-700 text-white text-[0.9rem] leading-[1rem] rounded hover:bg-sky-800 transition">arXiv </a><a href="https://github.com/prestonfu/qscaled" target="_blank" class="px-2 py-1 bg-sky-700 text-white text-[0.9rem] leading-[1rem] rounded hover:bg-sky-800 transition">Code </a><a href="https://x.com/_oleh/status/1889016893140516880" target="_blank" class="px-2 py-1 bg-sky-700 text-white text-[0.9rem] leading-[1rem] rounded hover:bg-sky-800 transition">Thread </a><a href="/assets/files/utd_scaling_poster_icml.pdf" target="_blank" class="px-2 py-1 bg-sky-700 text-white text-[0.9rem] leading-[1rem] rounded hover:bg-sky-800 transition">Poster </a></div></div></div>  </div>  </section></div></div> <div class="layout-md text-lg space-y-12"><div class="md-output space-y-6 svelte-1kj7go7"><div class="md-output svelte-1kj7go7"><!-- HTML_TAG_START --><p><strong>[motivation gif]</strong></p>
<p>Large models are slow and expensive to train, so we like to prototype research ideas on small scales before scaling up to larger budgets. This workflow assumes some guarantee of <em>predictability.</em> For example, the field has shown that language model pretraining <a href="https://arxiv.org/abs/2001.08361" class="link" target="_blank" rel="external noopener noreferrer">is predictable</a> — provided the &quot;right&quot; design decisions.</p>
<p>Scaling law research typically follows three steps:</p>
<ol>
<li>Within a budget, find the best-performing configuration for a given method (model architecture, algorithm), and verify that the <em>configuration and performance</em> scale predictably with the budget.</li>
<li>Repeat Step 1 for multiple methods, and select the one with the best predicted extrapolated performance.</li>
<li>Extrapolate this method&#39;s best-performing configuration to larger budgets, and check that performance matches the prediction.</li>
</ol>
<p>In supervised learning, these steps are enabled by the fact that training minimizes a loss over a fixed data distribution. This stability makes Step 1 tractable: once a configuration is tuned, its scaling behavior is smooth enough to trust the subsequent steps.</p>
<p>In online reinforcement learning (RL), however, Step 1 is far harder. Online RL updates its own data distribution over the course of training, adding instability at scale. This instability is the main obstacle to establishing predictability and, in turn, to enabling Steps 2 and 3.</p>
<p>We challenge this view and show that value-based RL does admit predictable scaling, with the right design decisions. By resolving the central difficulty of Step 1, we unlock the rest of the workflow.</p>
<p><video class="block mx-auto" aria-label="h1stand_3d.mp4" width="400px" controls playsinline><source src="/assets/images/h1stand_3d.mp4" type="video/mp4" /></video><p class='text-center text-gray-500 mb-4'>**Figure n.** Step 1: With the right configuration, data efficiency is predictable with respect to scaling axes, unlocking compute-optimal scaling.</p></p>
<h2 id="framework">Framework</h2><p>Scaling laws answer this question:</p>
<blockquote class="inline-block bg-neutral-50 border-l-4 border-neutral-600 rounded px-3 py-2 align-middle my-2"><p><em>Given a large, unseen budget of data and compute, how can we achieve the best possible performance?</em></p>
</blockquote><p>Let&#39;s examine the case of supervised learning, where scaling laws have already proved successful. To define the question more carefully: (i) what constitutes the budget, and (ii) what is our performance metric?</p>
<p>(i) A training compute (FLOPs) budget can be allocated along four axes:</p>
<p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>compute</mtext><mo>∝</mo><mtext>dataset size</mtext><mo>×</mo><mtext>epochs</mtext><mo>×</mo><mtext>batch size</mtext><mo>×</mo><mtext>model size</mtext></mrow><annotation encoding="application/x-tex">\text{compute} \propto \text{dataset size} \times \text{epochs} \times \text{batch size} \times \text{model size}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8095em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord">compute</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∝</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord text"><span class="mord">dataset size</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord">epochs</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord text"><span class="mord">batch size</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">model size</span></span></span></span></span></span></p>
<p>(ii) Performance is measured by the test loss.</p>
<p>Within this framework, the field of supervised learning has come to several key conclusions:</p>
<ul>
<li>Large models should not be trained to the lowest possible loss to be compute-optimal (Kaplan, 2020).</li>
<li>Scaling the batch size is useful for obtaining a more accurate estimate of the true gradient. However, there is a critical batch size in supervised learning, beyond which further increases in batch size yield minimal returns (McCandlish, 2018).</li>
<li>In data-constrained settings, you can train for <a href="https://arxiv.org/abs/2305.16264" class="link" target="_blank" rel="external noopener noreferrer">up to 4 epochs</a> before training on the same data yields diminishing returns (Muennighoff, 2023).</li>
</ul>
<p>Scaling law research proved fruitful once it leveraged <em>all of these observations together</em>. This enabled simple <a href="https://arxiv.org/abs/2001.08361" class="link" target="_blank" rel="external noopener noreferrer">power laws</a> (Kaplan, 2020) forecasting the loss in terms of model size and dataset size. Assuming the right batch size and epoch count, balancing between model size and dataset size laid the groundwork to train large models <a href="https://arxiv.org/abs/2203.15556" class="link" target="_blank" rel="external noopener noreferrer">compute-optimally</a> (Hoffman, 2022).</p>
<p>Similarly, RL scaling law research must first understand scaling along each axis before scaling them jointly.</p>
<h2 id="what-makes-rl-scaling-laws-different">What makes RL scaling laws different?</h2><p>Let&#39;s revisit our two prerequisite questions:</p>
<p>(i) In supervised learning, our data is collected a priori. Training assumes that the data is sampled i.i.d. from the dataset, and compute is spent uniformly over the data. In RL, we decompose the budget into two components: resources <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">D</mi></mrow><annotation encoding="application/x-tex">\mathcal D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span></span></span></span> (&quot;data&quot;) spent collecting data by interacting with an environment, and resources <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">C</mi></mrow><annotation encoding="application/x-tex">\mathcal C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.05834em;">C</span></span></span></span></span> (&quot;compute&quot;) spent training on the data. Although the amount of compute <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">C</mi></mrow><annotation encoding="application/x-tex">\mathcal C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.05834em;">C</span></span></span></span></span> is proportional to the amount of collected data <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">D</mi></mrow><annotation encoding="application/x-tex">\mathcal D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span></span></span></span>, in practice both procedures consume resources such as wall-clock time, and it is beneficial to define them separately. Depending on the domain of interest (e.g. language models or robotics), data will vary widely in terms of collection cost. Accordingly, we can define a budget <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">C</mi><mo>+</mo><mi>δ</mi><mo>⋅</mo><mi mathvariant="script">D</mi></mrow><annotation encoding="application/x-tex">\mathcal C + \delta \cdot \mathcal D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span></span></span></span>, where <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span></span> is defined separately for each use case.</p>
<p>(ii) The performance metric is an agent&#39;s Monte Carlo returns when interacting with an environment.</p>
<p>This setup gives us our problem statement:</p>
<blockquote class="inline-block bg-neutral-50 border-l-4 border-neutral-600 rounded px-3 py-2 align-middle my-2"><p><em>Given a limited budget</em> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">F</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\mathcal F_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.09931em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0993em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><em>, which may be a combination <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">C</mi><mo>+</mo><mi>δ</mi><mo>⋅</mo><mi mathvariant="script">D</mi></mrow><annotation encoding="application/x-tex">\mathcal C + \delta \cdot \mathcal D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span></span></span></span> of compute and data, how do we achieve the best possible performance</em> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>J</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">J^*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span><em>?</em></p>
</blockquote><p>In practice, this problem is hard to answer directly, since the reward structure can vary significantly across environments. Instead, we&#39;ll consider the dual problem. That is, we can define <strong>data efficiency</strong> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">D</mi><mi>J</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal D_J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> and <strong>compute efficiency</strong> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">C</mi><mi>J</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal C_J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0583em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> as the amounts of data and compute spent to achieve performance <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span></span></span></span></span>, respectively. Then, at the optimal <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>J</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">J^*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6887em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span>, we will have used up exactly the allocated budget: <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">F</mi><mn>0</mn></msub><mo>=</mo><msub><mi mathvariant="script">C</mi><msup><mi>J</mi><mo>∗</mo></msup></msub><mo>+</mo><mi>δ</mi><mo>⋅</mo><msub><mi mathvariant="script">D</mi><msup><mi>J</mi><mo>∗</mo></msup></msub></mrow><annotation encoding="application/x-tex">\mathcal F_0 = \mathcal C_{J^*} + \delta \cdot \mathcal D_{J^*}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.09931em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0993em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0583em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6183em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6183em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>. So, we can instead estimate <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">D</mi><mi>J</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal D_J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> and <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">C</mi><mi>J</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal C_J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0583em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> for multiple <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span></span></span></span></span>, then select the largest <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span></span></span></span></span> fitting within the budget.</p>
<blockquote class="inline-block bg-neutral-50 border-l-4 border-neutral-600 rounded px-3 py-2 align-middle my-2"><p><em>Given a performance threshold</em> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span></span></span></span></span>, <em>how can we allocate our resources to minimize the budget</em> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">C</mi><mi>J</mi></msub><mo>+</mo><mi>δ</mi><mo>⋅</mo><msub><mi mathvariant="script">D</mi><mi>J</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal C_J + \delta \cdot \mathcal D_J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0583em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><em>?</em></p>
</blockquote><p>Scaling laws have been <a href="https://arxiv.org/abs/2301.13442" class="link" target="_blank" rel="external noopener noreferrer">studied</a> for <strong>on-policy algorithms</strong> (Hilton, 2023), like PPO and GRPO. On-policy algorithms iteratively collect a batch of trajectories from the current policy <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span></span>, score those trajectories, and take a gradient step toward high-scoring trajectories (perhaps subject to constraints). At each iteration, once the update is done, the data must be thrown away (<strong>do we need a footnote?</strong>), and a new batch is collected from the new policy.</p>
<p>This last line highlights that on-policy algorithms are not data-efficient: we instead need off-policy RL algorithms, which able to learn from data collected by policies other than <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span></span>. In practice, however, scaling off-policy RL is tricky.</p>
<h3 id="off-policy-rl">Off-policy RL</h3><p>Modern instantiations of off-policy RL typically use a <strong>value function</strong> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q_\theta(s,a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span></span>, which decouple data collection from gradient updates. The learned value function is agnostic to the policy used to collect state-action transitions – instead, these transitions are sampled from a replay buffer <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">P</mi></mrow><annotation encoding="application/x-tex">\mathcal P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.08222em;">P</span></span></span></span></span>. In principle, the replay buffer can consist of <em>any</em> transitions – even if collected by another agent. In practice, the value network is bootstrapped by regressing onto a moving <strong>temporal distance (TD)-target</strong> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><mover accent="true"><mi>Q</mi><mo>ˉ</mo></mover><mo stretchy="false">(</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">r(s,a) + \gamma \bar Q(s&#x27;, a&#x27;)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0701em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8201em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">Q</span></span><span style="top:-3.2523em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>, where <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>Q</mi><mo>ˉ</mo></mover></mrow><annotation encoding="application/x-tex">\bar Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0145em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8201em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">Q</span></span><span style="top:-3.2523em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span></span> is produced via a moving average of the parameters of <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">Q_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> and is used for training stability. Putting this all together, the value function takes gradient steps on the <strong>TD error</strong>,</p>
<p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi mathvariant="double-struck">E</mi><mrow><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo separator="true">,</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo>∼</mo><mi mathvariant="script">P</mi><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>∼</mo><mi>π</mi><mo stretchy="false">(</mo><mo>⋅</mo><mi mathvariant="normal">∣</mi><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo></mrow></msub><mrow><mo fence="true">[</mo><msup><mrow><mo fence="true">(</mo><mi>r</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>+</mo><mi>γ</mi><mover accent="true"><mi>Q</mi><mo>ˉ</mo></mover><mo stretchy="false">(</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo>−</mo><msub><mi>Q</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo fence="true">)</mo></mrow><mn>2</mn></msup><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">L(\theta) = \mathbb{E}_{(s, a, s&#x27;) \sim \mathcal{P}, a&#x27; \sim \pi(\cdot|s&#x27;)}\left[ \left(r(s, a) + \gamma \bar{Q}(s&#x27;, a&#x27;) - Q_\theta(s, a) \right)^2\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em;"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">a</span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose mtight">)</span><span class="mrel mtight">∼</span><span class="mord mathcal mtight" style="margin-right:0.08222em;">P</span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mrel mtight">∼</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span><span class="mopen mtight">(</span><span class="mord mtight">⋅</span><span class="mord mtight">∣</span><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3552em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">[</span></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8201em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">Q</span></span><span style="top:-3.2523em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">)</span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.054em;"><span style="top:-3.3029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">]</span></span></span></span></span></span></span></p>
<p>However, bootstrapping onto TD-targets introduces additional scaling complexities:</p>
<ul>
<li>The TD-targets are moving because the parameters of <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>Q</mi><mo>ˉ</mo></mover></mrow><annotation encoding="application/x-tex">\bar Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0145em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8201em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">Q</span></span><span style="top:-3.2523em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span></span></span></span></span> are dependent on those of <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span></span>.</li>
<li>Replay introduces staleness because we revisit old transitions.</li>
</ul>
<p>However, this latter mechanic is exactly what makes TD-learning compelling in data-constrained regimes like robotics: we can reuse expensive experience many times. Intuitively, we can scale compute for a given amount of data by just taking multiple gradient steps on each batch sampled from the replay buffer. This knob is the <strong>updates-to-data ratio (UTD)</strong>.</p>
<p>Going back to question (i), we now have:</p>
<p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">C</mi><mi>J</mi></msub><mo>∝</mo><msub><mi mathvariant="script">D</mi><mi>J</mi></msub><mo>×</mo><mtext>UTD</mtext><mo>×</mo><mtext>batch size</mtext><mo>×</mo><mtext>model size</mtext></mrow><annotation encoding="application/x-tex">\mathcal C_J \propto \mathcal D_J  \times \text{UTD} \times \text{batch size} \times \text{model size}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0583em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∝</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord text"><span class="mord">UTD</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord text"><span class="mord">batch size</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">model size</span></span></span></span></span></span></p>
<p>Increasing the UTD ratio tends to improve performance for small UTD, but doing so naively can <a href="https://arxiv.org/abs/2205.07802" class="link" target="_blank" rel="external noopener noreferrer">eventually worsen</a> performance (Nikishin, 2022). How can we combat this?</p>
<p><strong>We argue that off-policy RL training is limited by overfitting.</strong> Specifically:</p>
<ul>
<li>For UTD scaling, we define &quot;overfitting&quot; as a metric for training data staleness.</li>
<li>For model size scaling, we define it as a metric for value function generalization.</li>
</ul>
<p>Empirically, we find that using the correct batch size can mitigate overfitting in each case and enables scaling to higher UTD and model sizes.</p>
<h2 id="how-do-i-set-my-hyperparameters">How do I set my hyperparameters?</h2><p>A key ingredient enabling language model scaling laws is the variety of theory and <a href="https://arxiv.org/abs/1404.5997" class="link" target="_blank" rel="external noopener noreferrer">practice</a> (Krizhevsky, 2014) establishing the relationship between optimal <a href="https://www.jmlr.org/papers/v20/18-789.html" class="link" target="_blank" rel="external noopener noreferrer">batch size</a> (Shallue, 2018), learning rate, and <a href="https://proceedings.neurips.cc/paper/2019/hash/e0eacd983971634327ae1819ea8b6214-Abstract.html" class="link" target="_blank" rel="external noopener noreferrer">optimizer</a> (Zhang, 2019). Put together, these trends enabled <a href="https://arxiv.org/abs/2203.03466" class="link" target="_blank" rel="external noopener noreferrer">hyperparameter transfer</a> (Yang, 2022) to unseen model sizes.</p>
<p>In our answer to this question, we unlock several surprising findings on off-policy RL training dynamics, which we later leverage to scale UTD and model size effectively.</p>
<h3 id="when-i-scale-the-utd">…when I scale the UTD?</h3><!-- HTML_TAG_END --></div><a href="#utd_scaling" class="block -mx-4 mb-4 px-4 py-2 bg-gray-100 hover:bg-slate-100 rounded transition"><span class="text-neutral-500" data-svelte-h="svelte-a7fxhe">↪</span> Our paper: <em>Value-Based Deep RL Scales Predictably</em></a><div class="md-output svelte-1kj7go7"><!-- HTML_TAG_START --><p>Let&#39;s first look at the case of UTD-only scaling at a constant model size. Empirically, we find that performance is most sensitive to changes in batch size and learning rate, and we&#39;ll focus on these hyperparameters.</p>
<p>Let&#39;s define &quot;overfitting&quot; as the difference between TD errors on data sampled uniformly at random from the replay buffer <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">P</mi></mrow><annotation encoding="application/x-tex">\mathcal P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathcal" style="margin-right:0.08222em;">P</span></span></span></span></span> and the data most recently added to the replay buffer. Intuitively, high UTD and high batch size both see the &quot;average&quot; sample more times and overfit to those samples. This results in higher relative TD error on data recently collected by the policy <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi></mrow><annotation encoding="application/x-tex">\pi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span></span></span></span></span>. We also observe this empirically! <strong>To counteract this effect, we decrease the batch size for higher UTD.</strong></p>
<p><img src="attachment:eb6c80d9-139f-4902-be17-8a766f0c5fa9:image.png" alt="image.png"></p>
<p><strong>Figure n:</strong> Overfitting increases with both UTD and batch size.</p>
<p>We also observe that high UTD ratios lead to <strong>plasticity loss</strong>, i.e. the inability to fit TD targets appearing later in training as a result of fitting them too much early on in training. Similarly, we observed that higher learning rates lead to high-magnitude updates against the target, moving the parameters to a state that would suffer from difficulty in fitting subsequent targets. Following <a href="https://openreview.net/forum?id=OpC-9aBBVJe" class="link" target="_blank" rel="external noopener noreferrer">prior work</a>, we empirically find that one diagnosis for plasticity loss is large parameter norm in the Q-network: increasing either UTD or learning rate corresponds to larger parameter norm. <strong>To counteract this effect, we decrease the learning rate for higher UTD, empirically following roughly a power law.</strong></p>
<p><img src="attachment:bb7379d4-d7f6-4884-a26f-4cc458373649:image.png" alt="image.png"></p>
<p><strong>Figure n:</strong> Parameter norm, a proxy for plasticity loss, increases with both UTD and learning rate.</p>
<!-- ```markdown -->

<!-- HTML_TAG_END --></div><div class="my-4 rounded bg-slate-50 hover:bg-sky-50/50 p-4 pb-1 border-l-4 border-sky-700 transition"><div class="text-xs font-semibold tracking-wide uppercase text-sky-700" data-svelte-h="svelte-8vdxxn">Takeaways</div> <div class="prose max-w-none mt-1"><div class="md-output"><!-- HTML_TAG_START --><ul>
<li>Decrease batch size with UTD. In our first paper, we showed empirically that it should
decay as a power law.</li>
<li>Decrease learning rate with UTD, also empirically following a power law.</li>
</ul>
<!-- HTML_TAG_END --></div></div></div><div class="md-output svelte-1kj7go7"><!-- HTML_TAG_START --><!-- ``` -->

<h3 id="when-i-scale-the-model-size">…when I scale the model size?</h3><!-- HTML_TAG_END --></div><a href="#model_scaling" class="block -mx-4 mb-4 px-4 py-2 bg-gray-100 hover:bg-slate-100 rounded transition"><span class="text-neutral-500" data-svelte-h="svelte-a7fxhe">↪</span> Our paper: <em>Compute-Optimal Scaling for Value-Based Deep RL</em></a><div class="md-output svelte-1kj7go7"><!-- HTML_TAG_START --><p>Let&#39;s now look at the case of model size scaling at a constant UTD.</p>
<p><strong>How does overfitting manifest with model size scaling?</strong> Here, instead of a metric for staleness, we&#39;ll directly measure the Q-network&#39;s generalization capabilities. To do so, we&#39;ll measure the TD error on both the training data and a held-out validation set of transitions drawn from a replay buffer with the same distribution (see Appendix B of <a href="https://arxiv.org/abs/2508.14881" class="link" target="_blank" rel="external noopener noreferrer">our new paper</a> for more details). It&#39;s helpful to look at these curves over the course of training, since in the practical implementation of TD-learning, value functions rarely fully fit the moving TD-targets. We show these learning curves in Figure n.</p>
<p><a href="attachment:7c5524ca-43df-407e-ab2e-1ef2bd45bb67:loss2x2_crawl.mp4" class="link" target="_blank" rel="external noopener noreferrer">loss2x2_crawl.mp4</a></p>
<p><strong>Figure n:</strong> Training and validation TD-errors reduce as model size increase. However, for smaller models, a larger batch size results in a higher final TD-error. This illustrates the role of batch size in modulating overfitting with TD-learning.</p>
<p>Unsurprisingly, increasing the batch size improves training TD-error. However, the effect on validation TD-error is more nuanced and depends on the model size. Why does this happen?</p>
<p><strong>Conceptual view:</strong> We argue that this is explained by the use of target networks in TD-learning, and coin this phenomenon <strong>TD-overfitting</strong>. Consider a smaller value function. Due to its low representational capacity, a model would entangle features used for predicting Q-values across multiple (state, action) pairs. As we scale up the batch size, this issue is exacerbated since these incorrect gradient updates become more &quot;directed&quot;. Fitting the Q-function, and hence the TD-targets, on some transitions comes at the expense of others.</p>
<p>By contrast, larger value functions produce features that can decouple its predictions across transitions, leading to improved generalization at larger batch sizes.</p>
<p><img src="attachment:b335cc9e-8611-4219-b7ab-6fc7df774e6f:image.png" alt="image.png"></p>
<p><strong>Figure n:</strong> Small models perform better with smaller batch sizes, which result in noisy updates, due to more directed gradient updates onto low-quality TD-targets. Larger models produce higher-quality TD targets and benefit from regressing to these targets better with larger batch sizes.</p>
<p><strong>Analysis:</strong> Check out <a href="https://arxiv.org/abs/2508.14881" class="link" target="_blank" rel="external noopener noreferrer">our new paper</a> (Section 5.3) for some really cool analysis of this phenomenon!</p>
<p><strong>So, how do I set my batch size?</strong> Empirically, we observe that the best batch size increases with model size, but eventually reaches an upward asymptote. Check out <a href="https://arxiv.org/abs/2508.14881" class="link" target="_blank" rel="external noopener noreferrer">our new paper</a> for our fit equation! Empirically we do not observe a significant interaction effect between UTD and model size, i.e. our fit factorizes into a power law decay in UTD and an upward asymptote in model size.</p>
<p><strong>How about other key hyperparameters?</strong> In <a href="https://arxiv.org/abs/2508.14881" class="link" target="_blank" rel="external noopener noreferrer">our new paper</a>, we additionally consider the effect of learning rate (Appendix D.2) and the target update rate (Appendix D.3). For &quot;reasonable&quot; selections of those hyperparameters, we found that data efficiency was most sensitive to changes in batch size.</p>
<pre><code class="language-markdown">Takeaways:

- TD-overfitting: Smaller models produce TD-targets that generalize poorly, and are
  hurt by large batch sizes.
- Larger models produce TD-targets that generalize well, and benefit from large
  batch sizes.
- The best batch size increases with model size, but is bounded above by an asymptote.
</code></pre>
<h2 id="budget-optimal-utd-scaling">Budget-optimal UTD scaling</h2><!-- HTML_TAG_END --></div><a href="#utd_scaling" class="block -mx-4 mb-4 px-4 py-2 bg-gray-100 hover:bg-slate-100 rounded transition"><span class="text-neutral-500" data-svelte-h="svelte-a7fxhe">↪</span> Our paper: <em>Value-Based Deep RL Scales Predictably</em></a><div class="md-output svelte-1kj7go7"><!-- HTML_TAG_START --><p>As before, we&#39;ll first consider UTD-only scaling at a constant model size. Armed with the best-choice batch size and learning rate, we can optimize the data efficiency. Empirically, we find that <strong>data efficiency scales as a power law with respect to UTD, across multiple domains, tasks, and algorithms</strong>!</p>
<p><img src="attachment:1525c1ec-0381-4839-be59-7e5ba87db711:image.png" alt="image.png"></p>
<p><strong>Figure n:</strong> Data efficiency scales as a power law with respect to UTD. Leveraging the batch size and learning rate fits asymptotically outperforms a constant baseline.</p>
<p>Finally, we are in a position to answer our question:</p>
<blockquote class="inline-block bg-neutral-50 border-l-4 border-neutral-600 rounded px-3 py-2 align-middle my-2"><p><em>Given a performance threshold</em> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span></span></span></span></span>, <em>what is the minimum achievable budget</em> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">C</mi><mi>J</mi></msub><mo>+</mo><mi>δ</mi><mo>⋅</mo><msub><mi mathvariant="script">D</mi><mi>J</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal C_J + \delta \cdot \mathcal D_J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0583em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>*, where the <strong>data efficiency*</strong> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">D</mi><mi>J</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal D_J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> *and <strong>compute efficiency*</strong> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">C</mi><mi>J</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal C_J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.05834em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0583em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.09618em;">J</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> <em>are the amounts of data and compute spent to achieve performance</em> <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span></span></span></span></span><em>?</em></p>
</blockquote><p><strong>Step 1:</strong> We can consider the amount of compute, in FLOPs, required to achieve a given performance threshold. For each threshold, there is a Pareto frontier defining the tradeoff between data and compute requirements, and the UTD defines the position along this curve. Along this Pareto frontier, there is a unique budget-minimizing selection of UTD. In our first paper, we showed that the budget-optimal partition between data and compute is predictable, as well as the budget-optimal UTD itself!</p>
<p><a href="attachment:d319bfea-1537-46e7-a7c7-6a3fd33b4717:_oleh_-_1889016893140516880.mp4" class="link" target="_blank" rel="external noopener noreferrer">_oleh - 1889016893140516880.mp4</a></p>
<p><strong>Step 3:</strong> We find that the budget-optimal UTD extrapolates well to larger budgets! <strong>Our method lets you predict the best data-compute tradeoff at unseen budgets.</strong></p>
<p><img src="attachment:39eff269-a2b6-4fee-a1ad-8fd0b69e83dc:image.png" alt="image.png"></p>
<pre><code class="language-markdown">Takeaways:

- Leveraging the batch size and learning rate fits, we find predictable power-law
  scaling in data efficiency versus UTD!
- For each threshold, the UTD defines a Pareto frontier between data and compute
  requirements.
- The budget-optimal UTD is predictable, following a power law in budget.
</code></pre>
<h2 id="budget-optimal-scaling-for-utd-and-model-size">Budget-optimal scaling for UTD and model size</h2><!-- HTML_TAG_END --></div><a href="#model_scaling" class="block -mx-4 mb-4 px-4 py-2 bg-gray-100 hover:bg-slate-100 rounded transition"><span class="text-neutral-500" data-svelte-h="svelte-a7fxhe">↪</span> Our paper: <em>Compute-Optimal Scaling for Value-Based Deep RL</em></a><div class="md-output svelte-1kj7go7"><!-- HTML_TAG_START --><p><strong>Step 1:</strong> Now, we&#39;ll additionally leverage our understanding of TD-overfitting via our batch size fit. Assuming this fit, we find that <strong>data efficiency scales as a sum of power laws with respect to the UTD and model size</strong>. (In Section 6 of <a href="https://arxiv.org/abs/2508.14881" class="link" target="_blank" rel="external noopener noreferrer">our new paper</a>, we also run a sensitivity analysis to show the importance of using the right batch size.)</p>
<p><a href="attachment:2934d9fb-ffab-4211-8912-1811754d1f85:data_iso_contour.mp4" class="link" target="_blank" rel="external noopener noreferrer">data_iso_contour.mp4</a></p>
<p><strong>Figure n:</strong> Each contour is the curve attaining the same fitted data efficiency to achieve a given target performance <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.09618em;">J</span></span></span></span></span>. The budget-optimal UTD and model size are marked with stars. Comparing <a href="https://arxiv.org/abs/2405.16158" class="link" target="_blank" rel="external noopener noreferrer">BRO</a> and <a href="https://arxiv.org/abs/2502.15280" class="link" target="_blank" rel="external noopener noreferrer">SimbaV2</a> completes <strong>Step 2</strong>.</p>
<p><strong>Step 3:</strong> Conveniently, our fit equation admits a closed-form solution for budget-optimal UTD and model size, in terms of the data efficiency! We find that, within a given budget, <strong>UTD-only scaling and model-size–only scaling use 11% and 26% more data, respectively</strong>, compared to the compute-optimal setting. In the paper, we similarly show that the data–compute partition is predictable at extrapolated budgets – check it out!</p>
<pre><code class="language-markdown">Takeaways:

- Leveraging our understanding of TD-overfitting improves model size scaling.
- Data efficiency can be modeled as a sum of power laws decaying in UTD and model size.
- Our fits tell you whether it is more compute-efficient to scale your UTD or model size.
</code></pre>
<h2 id="a-call-for-scalable-rl-algorithms">A call for scalable RL algorithms</h2><p>Scaling laws offer a blueprint for building reinforcement learning that scales. By identifying the scalable regime, we showed that value-based RL admits predictable scaling once its core instabilities, which manifest as overfitting, are resolved.</p>
<p>In supervised learning, scaling laws depend on the best choice of model size, batch size, and learning rate. In value-based RL, these relationships are much trickier to uncover, due to data distribution shift and the use of target networks in practice. These training dynamics are associated with a suite of parameters including the replay buffer size, optimizer, loss function (here distributional critic), and actor update frequency. Each new axis adds to the foundation for compute-optimal training, and in principle one could extend RL scaling law research to additional parameters and training regimes.</p>
<p>Ultimately, though, we must not only characterize existing methods, but also design better algorithms — ones that scale more reliably, across broader domains, and under more demanding budgets. The goal is not just to show that RL can scale, but to establish a general framework where scaling laws guide us toward the next generation of scalable RL algorithms.</p>
<!-- HTML_TAG_END --></div> </div></div> </div></main>  
			
			<script>
				{
					__sveltekit_16ja6l8 = {
						base: new URL(".", location).pathname.slice(0, -1)
					};

					const element = document.currentScript.parentElement;

					const data = [null,null];

					Promise.all([
						import("./_app/immutable/entry/start.DQ-iithN.js"),
						import("./_app/immutable/entry/app.DEWgKYMy.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 2],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
  </body>
</html>
